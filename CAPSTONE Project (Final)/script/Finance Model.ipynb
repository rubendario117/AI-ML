{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d58ad4",
   "metadata": {},
   "source": [
    "# ML & AI CAPSTONE Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eea402",
   "metadata": {},
   "source": [
    "In this notebook, we focus on enhancing the predictive performance of a ML Regression model used to predict the **Volumen** target variable based on several features.\n",
    "\n",
    "Since Volumen can be influence by a lot of external variables, we will focus our approach in determining the importance, relevance and/or influence of features (in this case, automotive industry's incentives) in the outcome, **Volumen**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58719568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37fe3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/Reporte_de_Incentivos_GM_AI.xlsx', header=0)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "517de464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL/SEGMENT</th>\n",
       "      <th>Date</th>\n",
       "      <th>UID</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Version</th>\n",
       "      <th>Model year</th>\n",
       "      <th>Body Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Doors</th>\n",
       "      <th>...</th>\n",
       "      <th>Free Mantenaince</th>\n",
       "      <th>Valid Since</th>\n",
       "      <th>Valid Until</th>\n",
       "      <th>Volumen</th>\n",
       "      <th>Plan Cost</th>\n",
       "      <th>Monthly Payment</th>\n",
       "      <th>Commission Cost</th>\n",
       "      <th>Insurance Cost</th>\n",
       "      <th>Total Finance</th>\n",
       "      <th>GM Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CORVETTE</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>8338421</td>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>1.5 A-SPEC CVT</td>\n",
       "      <td>2024</td>\n",
       "      <td>LB</td>\n",
       "      <td>Automático</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>9743.496252</td>\n",
       "      <td>22265.898498</td>\n",
       "      <td>19122.75</td>\n",
       "      <td>36216.52</td>\n",
       "      <td>28866.246252</td>\n",
       "      <td>Luxury Car-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENCLAVE/XT5/ACADIA</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>8302827</td>\n",
       "      <td>Acura</td>\n",
       "      <td>RDX</td>\n",
       "      <td>2.0 ADVANCE AUTO AWD</td>\n",
       "      <td>2023</td>\n",
       "      <td>OD</td>\n",
       "      <td>Automático</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>26</td>\n",
       "      <td>79244.032125</td>\n",
       "      <td>29197.215315</td>\n",
       "      <td>21373.10</td>\n",
       "      <td>37949.31</td>\n",
       "      <td>79244.032125</td>\n",
       "      <td>Luxury SUV-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENCLAVE/XT5/ACADIA</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>8019786</td>\n",
       "      <td>Acura</td>\n",
       "      <td>RDX</td>\n",
       "      <td>2.0 A-SPEC AUTO AWD</td>\n",
       "      <td>2023</td>\n",
       "      <td>OD</td>\n",
       "      <td>Automático</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>13</td>\n",
       "      <td>84175.210299</td>\n",
       "      <td>31014.092435</td>\n",
       "      <td>22703.10</td>\n",
       "      <td>39936.90</td>\n",
       "      <td>84175.210299</td>\n",
       "      <td>Luxury SUV-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEDAN</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>8226879</td>\n",
       "      <td>Acura</td>\n",
       "      <td>TLX</td>\n",
       "      <td>2.0 ADVANCE AUTO</td>\n",
       "      <td>2023</td>\n",
       "      <td>SA</td>\n",
       "      <td>Automático</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>3</td>\n",
       "      <td>12609.567637</td>\n",
       "      <td>28815.462711</td>\n",
       "      <td>24747.75</td>\n",
       "      <td>38314.80</td>\n",
       "      <td>37357.317637</td>\n",
       "      <td>Luxury Car-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEDAN</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>8306557</td>\n",
       "      <td>Acura</td>\n",
       "      <td>TLX</td>\n",
       "      <td>3.0 TYPE S AUTO AWD</td>\n",
       "      <td>2023</td>\n",
       "      <td>SA</td>\n",
       "      <td>Automático</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>15475.639022</td>\n",
       "      <td>35365.026924</td>\n",
       "      <td>30372.75</td>\n",
       "      <td>46007.44</td>\n",
       "      <td>45848.389022</td>\n",
       "      <td>Luxury Car-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MODEL/SEGMENT       Date      UID   Make    Model  \\\n",
       "0            CORVETTE 2023-07-01  8338421  Acura  Integra   \n",
       "1  ENCLAVE/XT5/ACADIA 2023-07-01  8302827  Acura      RDX   \n",
       "2  ENCLAVE/XT5/ACADIA 2023-07-01  8019786  Acura      RDX   \n",
       "3               SEDAN 2023-07-01  8226879  Acura      TLX   \n",
       "4               SEDAN 2023-07-01  8306557  Acura      TLX   \n",
       "\n",
       "                Version  Model year Body Type Transmission  Doors  ...  \\\n",
       "0        1.5 A-SPEC CVT        2024        LB   Automático      5  ...   \n",
       "1  2.0 ADVANCE AUTO AWD        2023        OD   Automático      5  ...   \n",
       "2   2.0 A-SPEC AUTO AWD        2023        OD   Automático      5  ...   \n",
       "3      2.0 ADVANCE AUTO        2023        SA   Automático      4  ...   \n",
       "4   3.0 TYPE S AUTO AWD        2023        SA   Automático      4  ...   \n",
       "\n",
       "   Free Mantenaince  Valid Since  Valid Until  Volumen     Plan Cost  \\\n",
       "0               0.0   2023-06-30   2023-07-31        1   9743.496252   \n",
       "1               0.0   2023-06-30   2023-07-31       26  79244.032125   \n",
       "2               0.0   2023-06-30   2023-07-31       13  84175.210299   \n",
       "3               0.0   2023-06-30   2023-07-31        3  12609.567637   \n",
       "4               0.0   2023-06-30   2023-07-31        1  15475.639022   \n",
       "\n",
       "   Monthly Payment  Commission Cost  Insurance Cost Total Finance  \\\n",
       "0     22265.898498         19122.75        36216.52  28866.246252   \n",
       "1     29197.215315         21373.10        37949.31  79244.032125   \n",
       "2     31014.092435         22703.10        39936.90  84175.210299   \n",
       "3     28815.462711         24747.75        38314.80  37357.317637   \n",
       "4     35365.026924         30372.75        46007.44  45848.389022   \n",
       "\n",
       "     GM Segment  \n",
       "0  Luxury Car-2  \n",
       "1  Luxury SUV-3  \n",
       "2  Luxury SUV-3  \n",
       "3  Luxury Car-3  \n",
       "4  Luxury Car-3  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "174e8926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16132 entries, 0 to 16131\n",
      "Data columns (total 38 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   MODEL/SEGMENT       16132 non-null  object        \n",
      " 1   Date                16132 non-null  datetime64[ns]\n",
      " 2   UID                 16132 non-null  int64         \n",
      " 3   Make                16132 non-null  object        \n",
      " 4   Model               16132 non-null  object        \n",
      " 5   Version             16132 non-null  object        \n",
      " 6   Model year          16132 non-null  int64         \n",
      " 7   Body Type           16132 non-null  object        \n",
      " 8   Transmission        16132 non-null  object        \n",
      " 9   Doors               16132 non-null  int64         \n",
      " 10  MSRP                16132 non-null  float64       \n",
      " 11  Final Price         16132 non-null  int64         \n",
      " 12  Down Payment        16132 non-null  float64       \n",
      " 13  Term Since          16132 non-null  float64       \n",
      " 14  Term Until          16132 non-null  float64       \n",
      " 15  Rate                16132 non-null  float64       \n",
      " 16  Residual            16132 non-null  float64       \n",
      " 17  Opening Commission  16132 non-null  float64       \n",
      " 18  Subsidized Plan     16132 non-null  object        \n",
      " 19  Name Plan           16132 non-null  object        \n",
      " 20  Plan Type           16132 non-null  object        \n",
      " 21  Discount            16132 non-null  float64       \n",
      " 22  Bonus               16132 non-null  float64       \n",
      " 23  Promotion 1         16132 non-null  object        \n",
      " 24  Promotion 2         16132 non-null  object        \n",
      " 25  Promotion 3         16132 non-null  object        \n",
      " 26  Insurance Free      16132 non-null  float64       \n",
      " 27  Free Commission     16132 non-null  float64       \n",
      " 28  Free Mantenaince    16132 non-null  float64       \n",
      " 29  Valid Since         16132 non-null  datetime64[ns]\n",
      " 30  Valid Until         16132 non-null  datetime64[ns]\n",
      " 31  Volumen             16132 non-null  int64         \n",
      " 32  Plan Cost           16132 non-null  float64       \n",
      " 33  Monthly Payment     16132 non-null  float64       \n",
      " 34  Commission Cost     16132 non-null  float64       \n",
      " 35  Insurance Cost      16132 non-null  float64       \n",
      " 36  Total Finance       16132 non-null  float64       \n",
      " 37  GM Segment          16132 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(17), int64(5), object(13)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ff85971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16132 entries, 0 to 16131\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MODEL/SEGMENT       16132 non-null  object \n",
      " 1   UID                 16132 non-null  int64  \n",
      " 2   Make                16132 non-null  object \n",
      " 3   Model               16132 non-null  object \n",
      " 4   Version             16132 non-null  object \n",
      " 5   Model year          16132 non-null  int64  \n",
      " 6   MSRP                16132 non-null  float64\n",
      " 7   Final Price         16132 non-null  int64  \n",
      " 8   Down Payment        16132 non-null  float64\n",
      " 9   Term Since          16132 non-null  float64\n",
      " 10  Term Until          16132 non-null  float64\n",
      " 11  Rate                16132 non-null  float64\n",
      " 12  Residual            16132 non-null  float64\n",
      " 13  Opening Commission  16132 non-null  float64\n",
      " 14  Subsidized Plan     16132 non-null  object \n",
      " 15  Plan Type           16132 non-null  object \n",
      " 16  Discount            16132 non-null  float64\n",
      " 17  Bonus               16132 non-null  float64\n",
      " 18  Insurance Free      16132 non-null  float64\n",
      " 19  Free Commission     16132 non-null  float64\n",
      " 20  Free Mantenaince    16132 non-null  float64\n",
      " 21  Volumen             16132 non-null  int64  \n",
      " 22  Plan Cost           16132 non-null  float64\n",
      " 23  Monthly Payment     16132 non-null  float64\n",
      " 24  Commission Cost     16132 non-null  float64\n",
      " 25  Insurance Cost      16132 non-null  float64\n",
      " 26  Total Finance       16132 non-null  float64\n",
      " 27  GM Segment          16132 non-null  object \n",
      "dtypes: float64(17), int64(4), object(7)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove Non-needed or irrelevant Columns\n",
    "columns_to_drop = ['Body Type','Transmission', 'Doors', 'Promotion 1','Promotion 2','Promotion 3','Name Plan']\n",
    "df_dropped = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Now I'll drop datetime cells for testing purposes:\n",
    "datetime_cols = ['Valid Since', 'Valid Until', 'Date']\n",
    "df_dropped = df_dropped.drop(columns=datetime_cols)\n",
    "\n",
    "df_dropped = df_dropped[df_dropped['GM Segment'] != '0']\n",
    "\n",
    "df_dropped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d4275e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16132 entries, 0 to 16131\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MODEL/SEGMENT       16132 non-null  object \n",
      " 1   UID                 16132 non-null  int64  \n",
      " 2   Make                16132 non-null  object \n",
      " 3   Model               16132 non-null  object \n",
      " 4   Version             16132 non-null  object \n",
      " 5   Model year          16132 non-null  int64  \n",
      " 6   MSRP                16132 non-null  float64\n",
      " 7   Final Price         16132 non-null  int64  \n",
      " 8   Down Payment        16132 non-null  float64\n",
      " 9   Term Since          16132 non-null  float64\n",
      " 10  Term Until          16132 non-null  float64\n",
      " 11  Rate                16132 non-null  float64\n",
      " 12  Residual            16132 non-null  float64\n",
      " 13  Opening Commission  16132 non-null  float64\n",
      " 14  Subsidized Plan     16132 non-null  int64  \n",
      " 15  Plan Type           16132 non-null  object \n",
      " 16  Discount            16132 non-null  float64\n",
      " 17  Bonus               16132 non-null  float64\n",
      " 18  Insurance Free      16132 non-null  float64\n",
      " 19  Free Commission     16132 non-null  float64\n",
      " 20  Free Mantenaince    16132 non-null  float64\n",
      " 21  Volumen             16132 non-null  int64  \n",
      " 22  Plan Cost           16132 non-null  float64\n",
      " 23  Monthly Payment     16132 non-null  float64\n",
      " 24  Commission Cost     16132 non-null  float64\n",
      " 25  Insurance Cost      16132 non-null  float64\n",
      " 26  Total Finance       16132 non-null  float64\n",
      " 27  GM Segment          16132 non-null  object \n",
      "dtypes: float64(17), int64(5), object(6)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# \"Fix\" the Boolean column Y/N to 1/0\n",
    "df_dropped['Subsidized Plan'] = df_dropped['Subsidized Plan'].replace({'Y':1 , 'N':0})\n",
    "df_dropped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d15c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now filter our DF based on the Segment. This will allow us to get more accurate predictions, based on each segment.\n",
    "segment_filter = df_dropped['GM Segment'] == 'Car-C'\n",
    "df_segment = df_dropped[segment_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4dec5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features, which are only the incentives, and target variable which is volume\n",
    "X = df_segment.loc[:, ['Insurance Cost', 'Commission Cost', 'Plan Cost', 'Free Mantenaince', 'Discount', 'Bonus' ]]\n",
    "y = df_segment['Volumen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49d7012c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insurance Cost</th>\n",
       "      <th>Commission Cost</th>\n",
       "      <th>Plan Cost</th>\n",
       "      <th>Free Mantenaince</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>24806.43</td>\n",
       "      <td>15445.690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>26349.41</td>\n",
       "      <td>16904.290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>20658.94</td>\n",
       "      <td>13632.750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>21977.40</td>\n",
       "      <td>14735.250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>19044.50</td>\n",
       "      <td>12282.750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>10440.59</td>\n",
       "      <td>9284.544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16107</th>\n",
       "      <td>10528.04</td>\n",
       "      <td>9047.792</td>\n",
       "      <td>11507.222426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16108</th>\n",
       "      <td>13064.84</td>\n",
       "      <td>7903.792</td>\n",
       "      <td>10822.089607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16109</th>\n",
       "      <td>10434.79</td>\n",
       "      <td>8319.792</td>\n",
       "      <td>11391.688214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16110</th>\n",
       "      <td>13320.53</td>\n",
       "      <td>12458.992</td>\n",
       "      <td>10970.379782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Insurance Cost  Commission Cost     Plan Cost  Free Mantenaince  \\\n",
       "139          24806.43        15445.690      0.000000               0.0   \n",
       "140          26349.41        16904.290      0.000000               0.0   \n",
       "247          20658.94        13632.750      0.000000               0.0   \n",
       "248          21977.40        14735.250      0.000000               0.0   \n",
       "249          19044.50        12282.750      0.000000               0.0   \n",
       "...               ...              ...           ...               ...   \n",
       "16077        10440.59         9284.544      0.000000               0.0   \n",
       "16107        10528.04         9047.792  11507.222426               0.0   \n",
       "16108        13064.84         7903.792  10822.089607               0.0   \n",
       "16109        10434.79         8319.792  11391.688214               0.0   \n",
       "16110        13320.53        12458.992  10970.379782               0.0   \n",
       "\n",
       "       Discount    Bonus  \n",
       "139         0.0  18000.0  \n",
       "140         0.0  18000.0  \n",
       "247         0.0      0.0  \n",
       "248         0.0      0.0  \n",
       "249         0.0      0.0  \n",
       "...         ...      ...  \n",
       "16077       0.0      0.0  \n",
       "16107       0.0      0.0  \n",
       "16108       0.0      0.0  \n",
       "16109       0.0      0.0  \n",
       "16110       0.0      0.0  \n",
       "\n",
       "[1196 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84582827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insurance Cost</th>\n",
       "      <th>Commission Cost</th>\n",
       "      <th>Plan Cost</th>\n",
       "      <th>Free Mantenaince</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>12158.930000</td>\n",
       "      <td>9160.200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>30840.770000</td>\n",
       "      <td>9100.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14187</th>\n",
       "      <td>12869.780000</td>\n",
       "      <td>7694.400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>33865.120000</td>\n",
       "      <td>11024.750</td>\n",
       "      <td>11089.807495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11363</th>\n",
       "      <td>11037.430000</td>\n",
       "      <td>7396.200</td>\n",
       "      <td>1389.560679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14192</th>\n",
       "      <td>10362.490000</td>\n",
       "      <td>5166.400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14940</th>\n",
       "      <td>10861.740000</td>\n",
       "      <td>6550.200</td>\n",
       "      <td>3124.302890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15363</th>\n",
       "      <td>11180.830000</td>\n",
       "      <td>7399.800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085</th>\n",
       "      <td>20698.490000</td>\n",
       "      <td>11608.200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15201</th>\n",
       "      <td>10848.955367</td>\n",
       "      <td>10962.875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14975.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Insurance Cost  Commission Cost     Plan Cost  Free Mantenaince  \\\n",
       "7703     12158.930000         9160.200      0.000000               0.0   \n",
       "1283     30840.770000         9100.000      0.000000               0.0   \n",
       "14187    12869.780000         7694.400      0.000000               0.0   \n",
       "2174     33865.120000        11024.750  11089.807495               0.0   \n",
       "11363    11037.430000         7396.200   1389.560679               0.0   \n",
       "...               ...              ...           ...               ...   \n",
       "14192    10362.490000         5166.400      0.000000               0.0   \n",
       "14940    10861.740000         6550.200   3124.302890               0.0   \n",
       "15363    11180.830000         7399.800      0.000000               0.0   \n",
       "12085    20698.490000        11608.200      0.000000               0.0   \n",
       "15201    10848.955367        10962.875      0.000000               0.0   \n",
       "\n",
       "       Discount    Bonus  \n",
       "7703        0.0      0.0  \n",
       "1283        0.0      0.0  \n",
       "14187    5000.0      0.0  \n",
       "2174        0.0      0.0  \n",
       "11363       0.0      0.0  \n",
       "...         ...      ...  \n",
       "14192    5000.0      0.0  \n",
       "14940       0.0      0.0  \n",
       "15363       0.0      0.0  \n",
       "12085       0.0      0.0  \n",
       "15201       0.0  14975.0  \n",
       "\n",
       "[956 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce415c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06817087104797981"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try first with a Linear Regression model\n",
    "lgr = LinearRegression().fit(X_train,y_train)\n",
    "lgr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39873357",
   "metadata": {},
   "source": [
    "As you can see, it seems a Linear Regression model is not suitable for my model. \n",
    "\n",
    "Pretty poor score. I'll switch to **Essemble Models** instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db0c280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score: 0.5255474735039196\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "random_forest_score = random_forest_model.score(X_test, y_test)\n",
    "print(\"Random Forest Score:\", random_forest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f2f19",
   "metadata": {},
   "source": [
    "#### How can we interpret this score?\n",
    "\n",
    "The **R2 value**, or the coefficient of determination, is a statistical measure that represents the proportion of the variance for the dependent variable that's explained by independent variables in a regression model. It provides a measure of how well the observed outcomes are replicated by the model based on the proportion of total variation of outcomes explained by the model.\n",
    "\n",
    "- R2 =1: The model perfectly predicts the target variable without any error.\n",
    "\n",
    "- R=0: The model is as good (or bad) as a model that simply predicts the mean of the target variable.\n",
    "\n",
    "- R<0: The model is worse than a model that simply predicts the mean of the target variable.\n",
    "\n",
    "\n",
    "In our case, Random Forest Score for **R2 = 0.5255**:\n",
    "\n",
    "This means that approximately 52.55% of the variability in the dependent variable (y_test) can be explained by the features (independent variables) in your model. In other words, the model accounts for 52.55% of the variance in the target variable. While this is better than a model with an R2 of 0 (which would mean it's no better than just predicting the mean of the target variable for all observations), there's still significant room for improvement, as the model doesn't capture almost half of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6bf5d",
   "metadata": {},
   "source": [
    "**Hyperparameter Tunig:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4d49a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300, 350, 400],\n",
    "    'max_depth': [None, 5, 10, 20, 30, 40, 50, 60],\n",
    "    'min_samples_leaf': [0.1, 0.5, 1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 25],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.5, 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, \n",
    "                           scoring='r2', cv=5, n_jobs=-1)\n",
    "\n",
    "# Perform grid search on the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best R-squared Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ffa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest model with the best parameters\n",
    "best_random_forest_model = RandomForestRegressor(\n",
    "    n_estimators=150,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=10,\n",
    "    max_features='auto',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the best model on the training data\n",
    "best_random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_random_forest_score = best_random_forest_model.score(X_test, y_test)\n",
    "print(\"Best Random Forest Score:\", best_random_forest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23996917",
   "metadata": {},
   "source": [
    "Let's try another approach on Hyperparameter Tuning:\n",
    "\n",
    "**Expand Grid Search:**\n",
    "\n",
    "- Wider Range: Let's the range of hyperparameters in your param_grid. Maybe there are better parameters outside the current range we've defined.\n",
    "- Randomized Search: Instead of an exhaustive grid search, use RandomizedSearchCV. It samples a given number of candidates from a parameter space with a specified distribution. This often leads to discovering better hyperparameters faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300, 350, 400],\n",
    "    'max_depth': [None, 5, 10, 20, 30, 40, 50, 60],\n",
    "    'min_samples_leaf': [0.1, 0.5, 1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 25],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.5, 0.7]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=random_forest_model, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # number of iterations\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters from Randomized Search:\", best_params_random)\n",
    "print(\"Best R-squared Score from Randomized Search:\", best_score_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe617f34",
   "metadata": {},
   "source": [
    "### Having a decent score, we can now start evaluating each of my features importance, which6 is the objective of my project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained Random Forest model\n",
    "feature_importances = best_random_forest_model.feature_importances_\n",
    "\n",
    "# Get the names of the features\n",
    "feature_names = X.columns\n",
    "\n",
    "# Sort the features based on importance\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X.shape[1]), feature_importances[sorted_indices])\n",
    "plt.xticks(range(X.shape[1]), [feature_names[i] for i in sorted_indices], rotation=90)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968aa82d",
   "metadata": {},
   "source": [
    "Having this, I 'll analyze each Segment and its feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of unique segments\n",
    "unique_segments = df_dropped['GM Segment'].unique()\n",
    "\n",
    "# Create an empty dataframe to store feature importances for each segment\n",
    "feature_importance_df = pd.DataFrame(columns=['Segment', 'Feature', 'Importance'])\n",
    "\n",
    "# Loop through each segment and analyze feature importances\n",
    "for segment in unique_segments:\n",
    "    segment_filter = df_dropped['GM Segment'] == segment\n",
    "    df_segment = df_dropped[segment_filter]\n",
    "    \n",
    "    # Separate features and target variable for the current segment\n",
    "    X_segment = df_segment.loc[:, ['Insurance Cost', 'Commission Cost', 'Plan Cost', 'Free Mantenaince', 'Discount', 'Bonus']]\n",
    "    y_segment = df_segment['Volumen']\n",
    "    \n",
    "    # Create a Random Forest model for the segment\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=10,\n",
    "        max_features='auto',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on the segment data\n",
    "    rf_model.fit(X_segment, y_segment)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    \n",
    "    # Add feature importances to the dataframe\n",
    "    for feature_idx, feature_name in enumerate(X_segment.columns):\n",
    "        feature_importance_df = feature_importance_df.append({\n",
    "            'Segment': segment,\n",
    "            'Feature': feature_name,\n",
    "            'Importance': feature_importances[feature_idx]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Display the dataframe with feature importances for each segment\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Optionally, save the dataframe to a CSV file\n",
    "feature_importance_df.to_csv('../output_data/feature_importances_by_segment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cd06d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now including MSRP into the analysis:\n",
    "\n",
    "# Get the list of unique segments\n",
    "unique_segments = df_dropped['GM Segment'].unique()\n",
    "\n",
    "# Create an empty dataframe to store feature importances for each segment\n",
    "feature_importance_df = pd.DataFrame(columns=['Segment', 'Feature', 'Importance'])\n",
    "\n",
    "# Loop through each segment and analyze feature importances\n",
    "for segment in unique_segments:\n",
    "    segment_filter = df_dropped['GM Segment'] == segment\n",
    "    df_segment = df_dropped[segment_filter]\n",
    "    \n",
    "    # Separate features and target variable for the current segment\n",
    "    X_segment = df_segment.loc[:, ['MSRP','Insurance Cost', 'Commission Cost', 'Plan Cost', 'Free Mantenaince', 'Discount', 'Bonus']]\n",
    "    y_segment = df_segment['Volumen']\n",
    "    \n",
    "    # Create a Random Forest model for the segment\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=10,\n",
    "        max_features='auto',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model on the segment data\n",
    "    rf_model.fit(X_segment, y_segment)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    \n",
    "    # Add feature importances to the dataframe\n",
    "    for feature_idx, feature_name in enumerate(X_segment.columns):\n",
    "        feature_importance_df = feature_importance_df.append({\n",
    "            'Segment': segment,\n",
    "            'Feature': feature_name,\n",
    "            'Importance': feature_importances[feature_idx]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Display the dataframe with feature importances for each segment\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Optionally, save the dataframe to a CSV file\n",
    "feature_importance_df.to_csv('../output_data/feature_importances_by_segment_(wMSRP).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35275da",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "\n",
    "I've done some research and SHAP (an acronym derived from SHapley Additive exPlanations) seems like an alternative to show features importance for my model.\n",
    "\n",
    "SHAP values provide a powerful way to interpret machine learning models, especially tree-based models like Random Forest or Gradient Boosted Trees. The idea is based on game theory, where the contribution of each feature to a prediction is fairly allocated.\n",
    "\n",
    "**Feature Importance:** The features are ordered by the sum of the SHAP value magnitudes over all samples. The most impactful feature is typically at the top, and the least impactful at the bottom. This provides a similar insight to feature importances in tree models, but with more nuance.\n",
    "\n",
    "**Feature Impact Direction:** For a given feature, a point to the right of the \"higher\" mark means the feature is contributing positively to the model's prediction for that instance.\n",
    "Conversely, a point to the left of the \"lower\" mark means it's contributing negatively.\n",
    "Feature Value Color:\n",
    "\n",
    "The color represents the value of the feature. For instance, if you have a binary feature, red might represent \"True\" and blue \"False\".\n",
    "For continuous features, the color scale (usually blue to red) will show whether a feature's value is high or low. Blue might represent lower values and red higher values, or vice versa depending on the default setting.\n",
    "Cluster of Points:\n",
    "\n",
    "If you see a cluster of points on the high end for a feature and they’re all red, it suggests that whenever that feature has high values, it tends to increase the model's prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c58a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_random_forest_model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d805a56",
   "metadata": {},
   "source": [
    "Now, let's have SHAP plots for every segment individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81258418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sanitize_dir_name(name):\n",
    "    str_name = str(name)  # Convert the input to a string\n",
    "    return ''.join(e for e in str_name if e.isalnum())\n",
    "\n",
    "# Ensure the main directory exists\n",
    "main_dir = '../images/SHAP'\n",
    "if not os.path.exists(main_dir):\n",
    "    os.makedirs(main_dir)\n",
    "\n",
    "# Get the list of unique segments\n",
    "unique_segments = df_dropped['GM Segment'].unique()\n",
    "\n",
    "# Loop through each segment and analyze using SHAP\n",
    "for segment in unique_segments:\n",
    "    print(f\"Processing segment: {segment}\")  # Debug print\n",
    "    \n",
    "    segment_filter = df_dropped['GM Segment'] == segment\n",
    "    df_segment = df_dropped[segment_filter]\n",
    "    \n",
    "    # Separate features and target variable for the current segment\n",
    "    X_segment = df_segment.loc[:, ['Insurance Cost', 'Commission Cost', 'Plan Cost', 'Free Mantenaince', 'Discount', 'Bonus']]\n",
    "    y_segment = df_segment['Volumen']\n",
    "    \n",
    "    # Create and train a Random Forest model for the segment\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=10,\n",
    "        max_features='auto',\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_segment, y_segment)\n",
    "    \n",
    "    # Compute SHAP values\n",
    "    explainer = shap.TreeExplainer(rf_model)\n",
    "    shap_values = explainer.shap_values(X_segment)\n",
    "    \n",
    "    # Ensure a directory for this segment exists\n",
    "    sanitized_segment = sanitize_dir_name(segment)\n",
    "    segment_dir = f'{main_dir}/{sanitized_segment}'\n",
    "    if not os.path.exists(segment_dir):\n",
    "        os.makedirs(segment_dir)\n",
    "    else:\n",
    "        print(f\"Directory {segment_dir} already exists.\")  # Debug print\n",
    "    \n",
    "    # Plot SHAP summary and save it as PNG\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_segment, show=False)\n",
    "    plt.savefig(f'{segment_dir}/summary_plot.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    #print(f\"Saved SHAP plot for segment: {segment}\")  # Debug print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea5d5",
   "metadata": {},
   "source": [
    "# Depth of Interpretation:\n",
    "\n",
    "Now, we will proceed and provide SHAP Dependence and SHAP Force Plots\n",
    "Let's break down the steps:\n",
    "\n",
    "Dependence Plots will be plotted for each feature for each segment. This shows the effect of a single feature across the whole dataset.\n",
    "\n",
    "Force Plots are typically for individual predictions. For this, I will demonstrate how to save a force plot for a single (e.g., the first) prediction in the dataset. Saving force plots for each instance in a segment could become excessive, depending on your dataset's size.\n",
    "\n",
    "\n",
    "**Summary Plot:** This is an aggregate of all the SHAP values for all the samples. It gives a high-level overview of feature importance and the direction of the relationship (positive or negative).\n",
    "\n",
    "**Dependence Plot:** You can also plot SHAP values of a single feature against the actual values of that feature. This helps in visualizing complex non-linear relationships which might not be immediately obvious.\n",
    "\n",
    "**Force Plot:** This breaks down the prediction for a single observation, showing which features pushed the model's prediction up or down, and by how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79db3aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to sanitize directory name\n",
    "def sanitize_dir_name(name):\n",
    "    return ''.join(e for e in str(name) if e.isalnum())\n",
    "\n",
    "# Directory for saving the SHAP plots\n",
    "main_dir = \"../images/SHAP\"\n",
    "\n",
    "# Get the list of unique segments (excluding '0')\n",
    "unique_segments = [segment for segment in df_dropped['GM Segment'].unique() if segment != '0']\n",
    "\n",
    "# Iterate over each segment\n",
    "for segment in unique_segments:\n",
    "    print(f\"Processing segment: {segment}\")\n",
    "    \n",
    "    # Filter the data for the current segment\n",
    "    segment_filter = df_dropped['GM Segment'] == segment\n",
    "    df_segment = df_dropped[segment_filter]\n",
    "    \n",
    "    # Check if columns exist and select only the available ones\n",
    "    available_features = ['Insurance Cost', 'Commission Cost', 'Plan Cost', 'Free Maintenance', 'Discount', 'Bonus']\n",
    "    selected_features = [feat for feat in available_features if feat in df_segment.columns]\n",
    "    \n",
    "    # Separate features and target variable\n",
    "    X_segment = df_segment.loc[:, selected_features]\n",
    "    y_segment = df_segment['Volumen']\n",
    "    \n",
    "    # Train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=10,\n",
    "        max_features='auto',\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_segment, y_segment)\n",
    "    \n",
    "    # Compute the SHAP values\n",
    "    explainer = shap.TreeExplainer(rf_model)\n",
    "    shap_values = explainer.shap_values(X_segment)\n",
    "    \n",
    "    # Ensure a directory for this segment exists\n",
    "    sanitized_segment = sanitize_dir_name(segment)\n",
    "    segment_dir = f'{main_dir}/{sanitized_segment}'\n",
    "    if not os.path.exists(segment_dir):\n",
    "        os.makedirs(segment_dir)\n",
    "    \n",
    "    # Create a SHAP Dependence plot for each feature\n",
    "    for feature in X_segment.columns:\n",
    "        shap.dependence_plot(\n",
    "            feature,\n",
    "            shap_values,\n",
    "            X_segment,\n",
    "            show=False\n",
    "        )\n",
    "        plt.savefig(f\"{segment_dir}/{feature}_dependence_plot.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    print(f\"Saved SHAP dependence plots for segment: {segment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d71763",
   "metadata": {},
   "source": [
    "##### Let's see a Dependance Plot for an specific segment and show how to interpret it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data for the segment \"Luxury Car-2\"\n",
    "segment_filter = df_dropped['GM Segment'] == 'Pickup-E'\n",
    "df_segment = df_dropped[segment_filter]\n",
    "\n",
    "# Define the columns of interest\n",
    "columns_of_interest = ['Insurance Cost', 'Commission Cost', 'Plan Cost', 'Discount', 'Bonus']\n",
    "\n",
    "# Separate features and target variable\n",
    "X_segment = df_segment.loc[:, columns_of_interest]\n",
    "y_segment = df_segment['Volumen']\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=150, max_depth=None, min_samples_split=2, random_state=42)\n",
    "rf_model.fit(X_segment, y_segment)\n",
    "\n",
    "# Create SHAP values using the trained model\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_segment)\n",
    "\n",
    "# Plot the SHAP Dependence Plot for \"Insurance Cost\"\n",
    "shap.dependence_plot(\"Insurance Cost\", shap_values, X_segment, display_features=X_segment)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17807db6",
   "metadata": {},
   "source": [
    "#### SHAP Dependance Plot Explanation:\n",
    "\n",
    "A SHAP Dependence Plot provides a visual understanding of the relationship between a single feature and the predicted outcome, while accounting for the effect of other features.\n",
    "\n",
    "Here’s a step-by-step interpretation guide:\n",
    "\n",
    "**1. Y-Axis (SHAP Value):**\n",
    "\n",
    "The Y-axis represents the SHAP value for a feature. A positive SHAP value pushes the model's prediction higher (more positive), while a negative SHAP value pushes the prediction lower (more negative).\n",
    "For a regression task, this means the model's output will increase or decrease. For a classification task, it means the probability of the positive class will increase or decrease.\n",
    "\n",
    "**2. X-Axis (Feature Value):**\n",
    "\n",
    "The X-axis displays the actual value of the feature for each instance in the dataset.\n",
    "\n",
    "**3. Dot Position:**\n",
    "\n",
    "Each dot represents an individual observation (row) in your dataset.\n",
    "The horizontal position of the dot shows the actual value of the feature for that observation.\n",
    "The vertical position indicates the SHAP value, showing how much that particular observation's feature value influenced the prediction.\n",
    "\n",
    "**4. Dot Color:**\n",
    "\n",
    "The color of the dots usually represents the value of another feature, providing a way to see interactions between the main feature and another feature. If a clear pattern emerges with the color of the dots, it suggests that the main feature's impact on the model's prediction changes depending on the value of another feature.\n",
    "\n",
    "**5. Vertical Spread:**\n",
    "\n",
    "If dots are scattered widely along the Y-axis for a specific value on the X-axis, it suggests high interaction effects between the selected feature and other features in the model.\n",
    "\n",
    "**6. Trend Line:**\n",
    "\n",
    "Some plots include a smoothed trend line. This line helps visualize the average effect of the feature value on the prediction.\n",
    "\n",
    "#### How to Use the Plot:\n",
    "\n",
    "- Feature Importance: Features with wider vertical spreads generally have a more significant impact on the model's prediction.\n",
    "\n",
    "- Feature Interaction: If the color of the dots (representing another feature's value) shows a clear pattern or trend, it's an indication of interaction between the main feature and the feature represented by the color.\n",
    "\n",
    "- Non-linearity: If the trend line isn't straight or has curves, it suggests that the model captures a non-linear relationship between the feature and the predicted outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data for the segment \"Luxury Car-2\"\n",
    "segment_filter = df_dropped['GM Segment'] == 'Pickup-E'\n",
    "df_segment = df_dropped[segment_filter]\n",
    "\n",
    "# Define the columns of interest\n",
    "columns_of_interest = ['Insurance Cost', 'Commission Cost', 'Plan Cost', 'Discount', 'Bonus']\n",
    "\n",
    "# Separate features and target variable\n",
    "X_segment = df_segment.loc[:, columns_of_interest]\n",
    "y_segment = df_segment['Volumen']\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=10,\n",
    "        max_features='auto',\n",
    "        random_state=42\n",
    ")\n",
    "    \n",
    "rf_model.fit(X_segment, y_segment)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the explainer\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "\n",
    "base_value = explainer.expected_value\n",
    "\n",
    "single_instance_shap_values = shap_values[0]\n",
    "\n",
    "\n",
    "# Calculate SHAP values for the segment\n",
    "shap_values = explainer.shap_values(X_segment)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(base_value, single_instance_shap_values, X_segment.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511475d3",
   "metadata": {},
   "source": [
    "#### SHAP Force Plot Explanation:\n",
    "\n",
    "SHAP force plots provide an intuitive way to understand individual predictions by decomposing them into contributions from each feature. Let's break down how to interpret a force plot:\n",
    "\n",
    "**1. Components of a Force Plot:**\n",
    "\n",
    "- Base Value: This is the starting point of the prediction, which represents the average prediction for all instances in the training set.\n",
    "\n",
    "- Output Value: This is the end value of the force plot, which is the actual prediction for the specific instance you're inspecting.\n",
    "\n",
    "- Features: These are the individual factors pushing the prediction higher or lower compared to the base value. Each feature in the force plot has a weight (or force) associated with it, which is visually represented by the width of the arrow.\n",
    "\n",
    "- Arrows (or Forces):\n",
    "\n",
    "-  Red Arrows: These show the features that are pushing the prediction to increase from the base value. The wider the arrow, the larger the impact of that feature.\n",
    "-  Blue Arrows: These represent features that push the prediction to decrease from the base value.\n",
    "\n",
    "**2. Interpretation Steps:**\n",
    "\n",
    "- Start with the Base Value: This is the model's prediction if it only considered the average of the dataset without any specific features of the instance in question. You can think of it as the \"neutral\" or \"starting\" prediction.\n",
    "\n",
    "- Follow the Arrows: Look at the features and their corresponding arrows. They tell you which features had the most impact (positive or negative) on the prediction. The width of each arrow indicates the magnitude of the feature's impact.\n",
    "\n",
    "- Compare Red vs. Blue: The balance of red (positive impact) and blue (negative impact) arrows will push the prediction from the base value towards the final output value.\n",
    "\n",
    "- Final Output Value: At the end of all the arrows, you'll reach the model's actual prediction for that instance. It's the result of the base value plus all the positive and negative forces.\n",
    "\n",
    "**3. Practical Insights:**\n",
    "\n",
    "- Important Features: The most influential features for a given prediction are the ones with the widest arrows. By looking at these, you can quickly determine which factors most influenced a specific prediction.\n",
    "\n",
    "- Unexpected Behaviors: If you're familiar with the domain, you can use the force plot to identify when the model is relying heavily on features that don't make intuitive sense. This can be an indicator of potential issues with the data or model.\n",
    "\n",
    "- Contrastive Explanations: By comparing force plots of different instances, you can understand why the model predicted different values for them. It provides a contrastive explanation by highlighting which features differed most between instances.\n",
    "\n",
    "**4. Limitations:**\n",
    "\n",
    "- Overwhelming with Too Many Features: If the model has a large number of features, the force plot can become cluttered. It's often helpful to focus on the top N most influential features to make interpretation more manageable.\n",
    "\n",
    "\n",
    "In summary, SHAP force plots are powerful tools for understanding the intricate details of individual predictions. They highlight the interplay of features in shaping the prediction, providing valuable insights for both experts and non-experts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
